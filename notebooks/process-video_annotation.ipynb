{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imports'''\n",
    "# setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# stblib\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "\n",
    "# thirdparty\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# detectron2 utils\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''directory setup'''\n",
    "tmp_dir = os.path.join('tmp', 'video_annotation')\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "print(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load video'''\n",
    "# USER INPUT\n",
    "video_name = 'highway-4k.mp4'\n",
    "\n",
    "# load video\n",
    "video_input = os.path.join(tmp_dir, video_name)\n",
    "video = cv2.VideoCapture(video_input)\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(video_input)\n",
    "print(\"%s, #frames = %d, fps = %.01f, w = %d, h = %d\" % (video, num_frames, frames_per_second, width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''frames generator for video processing'''\n",
    "def _video_frame_generator(cv2_video_capture):\n",
    "    while video.isOpened():\n",
    "        success, frame = cv2_video_capture.read()\n",
    "        if success:\n",
    "            yield frame\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''set up trained detectron model'''\n",
    "# USER INPUT\n",
    "hw_map = 'cpu'  # map process to 'cpu' or 'gpu'\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Cityscapes/mask_rcnn_R_50_FPN.yaml\"))\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # overwrite detection threshold for this model\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Cityscapes/mask_rcnn_R_50_FPN.yaml\")\n",
    "cfg.MODEL.DEVICE = hw_map\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# inspect metadata\n",
    "print(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loop over video and save detections'''\n",
    "# USER INPUT\n",
    "max_frames = 10000\n",
    "\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "instance_classes = metadata.get('thing_classes', None)\n",
    "\n",
    "video_annotation = OrderedDict()\n",
    "\n",
    "for frame_id, frame in tqdm(enumerate(_video_frame_generator(video))):\n",
    "    if frame_id + 1 > max_frames:\n",
    "        break\n",
    "    # get ouput lists\n",
    "    outputs = predictor(frame)\n",
    "    outputs_cpu = outputs[\"instances\"].to(\"cpu\")\n",
    "    outputs_zipped = zip(outputs_cpu.pred_classes, outputs_cpu.pred_masks, outputs_cpu.pred_boxes, outputs_cpu.scores)\n",
    "    # register frame annotation\n",
    "    frame_path = 'frame_%04d' % frame_id\n",
    "    video_annotation[frame_path] = OrderedDict()\n",
    "    frame_dict = video_annotation[frame_path]\n",
    "    for instance_id, (class_id, mask, bbox, score) in enumerate(outputs_zipped):\n",
    "        instance_path = 'instace_%02d' % instance_id\n",
    "        frame_dict[instance_path] = OrderedDict()\n",
    "        frame_dict[instance_path]['class_id'] = class_id.item()\n",
    "        frame_dict[instance_path]['class_name'] = instance_classes[class_id]\n",
    "    #     frame_dict[instance_path]['mask'] = mask.numpy()\n",
    "        frame_dict[instance_path]['bbox'] = bbox.numpy()\n",
    "        frame_dict[instance_path]['score'] = score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save frame annotation as npz\n",
    "\n",
    "data structure:\n",
    "{\n",
    "    frame_<id> : {\n",
    "        instance_<id> : {\n",
    "            class_id : <id>,\n",
    "            class_name : <name>,\n",
    "            # mask : <mask>,\n",
    "            bbox : <coords>,\n",
    "            score : <score>,\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "'''\n",
    "video_label_file = os.path.join(tmp_dir, '%s.npz' % video_name)\n",
    "np.savez(video_label_file, **video_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load data again to verify correctness'''\n",
    "video_labels = OrderedDict(np.load(video_label_file, allow_pickle=True))\n",
    "pprint(video_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
